# -*- coding: utf-8 -*-
"""
Created on Sun Aug 29 17:08:18 2021

@author: Patrick Ledoit
"""


# function sigmahat=covCor(Y,k)
#
# Y (N*p): raw data matrix of N iid observations on p random variables
# sigmahat (p*p): invertible covariance matrix estimator
#
# Shrinks towards constant-correlation matrix:
#    the target preserves the variances of the sample covariance matrix
#    all the correlation coefficients of the target are the same
#
# If the second (optional) parameter k is absent, not-a-number, or empty,
# then the algorithm demeans the data by default, and adjusts the effective
# sample size accordingly. If the user inputs k = 0, then no demeaning
# takes place; if (s)he inputs k = 1, then it signifies that the data Y has
# already been demeaned.
#
# This version: 01/2021, based on the 04/2014 version

###########################################################################
# This file is released under the BSD 2-clause license.

# Copyright (c) 2014-2021, Olivier Ledoit and Michael Wolf
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are
# met:
#
# 1. Redistributions of source code must retain the above copyright notice,
# this list of conditions and the following disclaimer.
#
# 2. Redistributions in binary form must reproduce the above copyright
# notice, this list of conditions and the following disclaimer in the
# documentation and/or other materials provided with the distribution.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS
# IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
# THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
# PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR
# CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
# EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
# PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
# LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
# NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
###########################################################################
def covCor(d, k=None) :
    # Pre-Conditions: Y is a valid pd.dataframe and optional arg- k which can be
    #    None, np.nan or int
    # Post-Condition: Sigmahat dataframe is returned

    import numpy as np
    import numpy.matlib as mt
    import pandas as pd
    import math

    # de-mean returns if required
    d = d.copy()
    #Y = pd.DataFrame(d).astype(float).pct_change().dropna()
    Y = pd.DataFrame(d).astype(float)


    N, p = Y.shape  # sample size and matrix dimension

    # correct for fact that returns instead of prices are used (first entry missing)



    # default setting
    if k is None or math.isnan(k) :
        mean = Y.mean(axis=0)
        Y = Y.sub(mean, axis=1)  # demean
        k = 1

    # vars
    n = N  # adjust effective sample size

    # Cov df: sample covariance matrix
    sample = pd.DataFrame(np.matmul(Y.T.to_numpy(), Y.to_numpy())) / n

    # compute shrinkage target
    samplevar = np.diag(sample.to_numpy())
    sqrtvar = pd.DataFrame(np.sqrt(samplevar))
    rBar = (np.sum(np.sum(sample.to_numpy() / np.matmul(sqrtvar.to_numpy(), sqrtvar.T.to_numpy()))) - p) / (
                p * (p - 1))  # mean correlation
    target = pd.DataFrame(rBar * np.matmul(sqrtvar.to_numpy(), sqrtvar.T.to_numpy()))
    target[np.logical_and(np.eye(p), np.eye(p))] = sample[np.logical_and(np.eye(p), np.eye(p))];

    # estimate the parameter that we call pi in Ledoit and Wolf (2003, JEF)
    Y2 = pd.DataFrame(np.multiply(Y.to_numpy(), Y.to_numpy()))
    sample2 = pd.DataFrame(np.matmul(Y2.T.to_numpy(), Y2.to_numpy())) / n  # sample covariance matrix of squared returns
    piMat = pd.DataFrame(sample2.to_numpy() - np.multiply(sample.to_numpy(), sample.to_numpy()))
    pihat = sum(piMat.sum())

    # estimate the parameter that we call gamma in Ledoit and Wolf (2003, JEF)
    gammahat = np.linalg.norm(sample.to_numpy() - target, ord='fro') ** 2

    # diagonal part of the parameter that we call rho
    rho_diag = np.sum(np.diag(piMat))

    # off-diagonal part of the parameter that we call rho
    term1 = pd.DataFrame(np.matmul((Y ** 3).T.to_numpy(), Y.to_numpy()) / n)
    term2 = pd.DataFrame(np.transpose(mt.repmat(samplevar, p, 1)) * sample)
    thetaMat = term1 - term2
    thetaMat[np.logical_and(np.eye(p), np.eye(p))] = pd.DataFrame(np.zeros((p, p)))[
        np.logical_and(np.eye(p), np.eye(p))]
    rho_off = rBar * (np.matmul((1 / sqrtvar).to_numpy(), sqrtvar.T.to_numpy()) * thetaMat).sum().sum()

    # compute shrinkage intensity
    rhohat = rho_diag + rho_off
    kappahat = (pihat - rhohat) / gammahat
    shrinkage = max(0, min(1, kappahat / n))

    # compute shrinkage estimator
    sigmahat = shrinkage * target + (1 - shrinkage) * sample

    sigmahat = sigmahat.to_numpy()

    return sigmahat, shrinkage

if __name__ == "__main__":
    import pandas as pd
    bgn_date = "1990-01-29"
    end_date = "2020-01-01"
    nassets = 9
    file_path = "C:\\Universit√§t\\Numerical Methods\\prcs.csv"
    rets_df = pd.read_csv(file_path, parse_dates=['date'], index_col=["date"]).pct_change()[bgn_date: end_date].iloc[:, 0: nassets]
    rets = rets_df.values
    covMat,shrinkage= covCor(rets)
    print(covMat)

